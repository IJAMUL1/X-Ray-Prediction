{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7443f76-aa7b-48db-b15f-097fadc15b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms as T,datasets,models\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.nn import Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23983dd6-9bde-4153-8a14-1a38bef83dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transforms(phase = None):\n",
    "    \n",
    "    if phase == 'train':\n",
    "\n",
    "        data_T = T.Compose([\n",
    "            \n",
    "                T.Resize(size = (256,256)),\n",
    "                T.RandomRotation(degrees = (-20,+20)),\n",
    "                T.CenterCrop(size=224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "\n",
    "        data_T = T.Compose([\n",
    "\n",
    "                T.Resize(size = (224,224)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    return data_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2e5664-95f4-4206-bb2b-f63f3eb49e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/Anil/Downloads/archive/chest_xray\"\n",
    "\n",
    "trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'),transform = data_transforms('train'))\n",
    "testset = datasets.ImageFolder(os.path.join(data_dir, 'test'),transform = data_transforms('test'))\n",
    "validset = datasets.ImageFolder(os.path.join(data_dir, 'val'),transform = data_transforms('val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c0be92-1974-4f4a-943e-ff36b11cb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f962802f-e7f9-424d-950d-526530b5d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset,batch_size = 64,shuffle = True)\n",
    "validloader = DataLoader(validset,batch_size = 64,shuffle = True)\n",
    "testloader = DataLoader(testset,batch_size = 64,shuffle = True)\n",
    "\n",
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc998bc-1dc0-4ac3-981c-bdd84a054ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images,labels) in enumerate(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7806aff4-e905-4338-aa1c-7996fabf20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 64, (4, 4), (2, 2), (1, 1), bias=True),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(64, 128, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(128, 256, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(256, 512, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(512, 1, (4, 4), (1, 1), (0, 0), bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        out = torch.flatten(out, 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3ab70e-2cd9-4189-98aa-f8421af70a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69368adc-4439-4233-bfa4-068844472f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dbfdb4-2509-4d16-a23c-52ea9a068e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f5419d-bd19-459d-8304-e9af71504596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f3365a-fb02-4ebd-9d38-89487418354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           3,136\n",
      "         LeakyReLU-2         [-1, 64, 112, 112]               0\n",
      "            Conv2d-3          [-1, 128, 56, 56]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 56, 56]             256\n",
      "         LeakyReLU-5          [-1, 128, 56, 56]               0\n",
      "            Conv2d-6          [-1, 256, 28, 28]         524,288\n",
      "       BatchNorm2d-7          [-1, 256, 28, 28]             512\n",
      "         LeakyReLU-8          [-1, 256, 28, 28]               0\n",
      "            Conv2d-9          [-1, 512, 14, 14]       2,097,152\n",
      "      BatchNorm2d-10          [-1, 512, 14, 14]           1,024\n",
      "        LeakyReLU-11          [-1, 512, 14, 14]               0\n",
      "           Conv2d-12            [-1, 1, 11, 11]           8,193\n",
      "          Sigmoid-13            [-1, 1, 11, 11]               0\n",
      "================================================================\n",
      "Total params: 2,765,633\n",
      "Trainable params: 2,765,633\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 28.33\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 39.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (images.shape[1], images.shape[2], images.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca22321b-b65e-4e06-9e39-e081de016a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 3.9871963989443895\n",
      "Epoch 2 - Training loss: 3.902917783434798\n",
      "Epoch 3 - Training loss: 3.895060623564371\n",
      "Epoch 4 - Training loss: 3.882996454471495\n",
      "Epoch 5 - Training loss: 3.8722757798869436\n"
     ]
    }
   ],
   "source": [
    "Losses = []\n",
    "for i in range(5): #I noticed very little change in the loss, so keeping the epochs low\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        Losses.append(loss)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e94469c5-de8a-4993-800a-9305681603f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 624\n",
      "\n",
      "Model Accuracy = 0.3798076923076923\n"
     ]
    }
   ],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images,labels in testloader:\n",
    "  for i in range(len(labels)):\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "    img = images[i].view(1, 3, 224, 224)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.cpu()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.cpu()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383fd97-865b-4c93-824f-24a5f4ed9952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
