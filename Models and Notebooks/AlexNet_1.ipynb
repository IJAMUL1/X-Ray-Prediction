{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5913e41f-69fa-45ea-aedc-98ea57b0aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 8994.895396574875\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 2/10, Loss: 0.578229151986128\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 3/10, Loss: 0.576345131989637\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 4/10, Loss: 0.5723655640713277\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 5/10, Loss: 0.5744302254512997\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 6/10, Loss: 0.577804655568\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 7/10, Loss: 0.5741228411899754\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 8/10, Loss: 0.5731082927961291\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 9/10, Loss: 0.5730826386644796\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 10/10, Loss: 0.5737838845677171\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained AlexNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fea948-69e9-49d7-8a08-932facf6f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 16582.40515058081\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 2/5, Loss: 0.579979658126831\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 3/5, Loss: 0.5770615026629045\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 4/5, Loss: 0.5740941700759841\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 5/5, Loss: 0.5735539007771966\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained AlexNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99ef6a5-769e-40ab-8fbe-37636d1e5a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 20605.121907937748\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 2/20, Loss: 0.589285872282426\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 3/20, Loss: 0.575228200002682\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 4/20, Loss: 0.5747416617314508\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 5/20, Loss: 0.5732662072576629\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 6/20, Loss: 0.5755047549499325\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 7/20, Loss: 0.5801397680870595\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 8/20, Loss: 0.5741562724479137\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 9/20, Loss: 0.5748016263809672\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 10/20, Loss: 0.571996669462122\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 11/20, Loss: 0.570320859642848\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 12/20, Loss: 0.5718472749909009\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 13/20, Loss: 0.5724673960472177\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 14/20, Loss: 0.5723418357547807\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 15/20, Loss: 0.5715988474023854\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 16/20, Loss: 0.5729570140136532\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 17/20, Loss: 0.5712376706804966\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 18/20, Loss: 0.572329798359081\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 19/20, Loss: 0.5720330913739702\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 20/20, Loss: 0.5720060294025515\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained AlexNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f790403-8f29-4036-ac80-2ca884a3e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6095968570811617\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 2/5, Loss: 0.5741393878781722\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 3/5, Loss: 0.5736043264895129\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 4/5, Loss: 0.5746709836041269\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 5/5, Loss: 0.573343422698097\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained AlexNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a15658aa-087a-4688-94be-faf691df527a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6015813016086999\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 2/10, Loss: 0.572345851389177\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 3/10, Loss: 0.5731681002063985\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 4/10, Loss: 0.5727615500886016\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 5/10, Loss: 0.5740144539830143\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 6/10, Loss: 0.5724700546703456\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 7/10, Loss: 0.5727748649617646\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 8/10, Loss: 0.5736285660164487\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 9/10, Loss: 0.5731082410534467\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 10/10, Loss: 0.571410939920168\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained AlexNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a859de3e-3d33-4ac2-80ef-c1e6ff003c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6983449565121002\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 2/20, Loss: 0.5741199439654321\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 3/20, Loss: 0.573803893810401\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 4/20, Loss: 0.5741305925363412\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 5/20, Loss: 0.5748436829429463\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 6/20, Loss: 0.5730342881445505\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 7/20, Loss: 0.5708492164231517\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 8/20, Loss: 0.5712597445110602\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 9/20, Loss: 0.5725457586028093\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 10/20, Loss: 0.5739966535860775\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 11/20, Loss: 0.5721741386352142\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 12/20, Loss: 0.5730212882983904\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 13/20, Loss: 0.5716932847455967\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 14/20, Loss: 0.5725534229190803\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 15/20, Loss: 0.5717539152850403\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 16/20, Loss: 0.5721135325958392\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 17/20, Loss: 0.5718662971002193\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 18/20, Loss: 0.5717587719665714\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 19/20, Loss: 0.5721693673382507\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 20/20, Loss: 0.5725231582036048\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained AlexNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7bd5c48-6f22-4574-9007-d2019f18e68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6425753329063486\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 2/20, Loss: 0.575569212436676\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 3/20, Loss: 0.5714464639227814\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 4/20, Loss: 0.5724187848026767\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 5/20, Loss: 0.5731204856027123\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 6/20, Loss: 0.573713638116977\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 7/20, Loss: 0.5711681031010634\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 8/20, Loss: 0.5735202747985629\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 9/20, Loss: 0.5728176980296527\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 10/20, Loss: 0.5720699729363611\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 11/20, Loss: 0.5712563856247744\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 12/20, Loss: 0.5723329702037975\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 13/20, Loss: 0.5719697182895216\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 14/20, Loss: 0.5722438647337487\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 15/20, Loss: 0.5724268423999014\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 16/20, Loss: 0.5728542769979115\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 17/20, Loss: 0.5703884761757646\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 18/20, Loss: 0.5725782970709303\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 19/20, Loss: 0.5714592346750154\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n",
      "Epoch 20/20, Loss: 0.5722118707522292\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "#finally used this one in the report\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(10),      # Randomly rotate the images by 10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation and Test transform does not need augmentation, only resizing and normalization\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply the updated transforms to datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained AlexNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e535dd-35e8-477c-aef5-29dfe05c0559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
