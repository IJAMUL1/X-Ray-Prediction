{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0c0fe6-d6da-4386-8daf-573f74c4e5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pb2718/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/pb2718/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.1277664280039447\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 88.28125%\n",
      "Epoch 2/5, Loss: 0.06433201146289204\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 75.46875%\n",
      "Epoch 3/5, Loss: 0.04343119036460558\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 79.53125%\n",
      "Epoch 4/5, Loss: 0.026367703330488105\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 86.5625%\n",
      "Epoch 5/5, Loss: 0.04696813619844158\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 64.21875%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a125237-fd36-46f9-89ce-b3fe2afbf72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.10754708391957077\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 87.96875%\n",
      "Epoch 2/10, Loss: 0.05927979349490095\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 63.59375%\n",
      "Epoch 3/10, Loss: 0.05814611573455044\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 77.96875%\n",
      "Epoch 4/10, Loss: 0.0375474030276949\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 86.40625%\n",
      "Epoch 5/10, Loss: 0.03131021585878259\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 82.65625%\n",
      "Epoch 6/10, Loss: 0.01400764680444245\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 68.4375%\n",
      "Epoch 7/10, Loss: 0.04733486599452255\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 87.65625%\n",
      "Epoch 8/10, Loss: 0.024647834565436205\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 77.03125%\n",
      "Epoch 9/10, Loss: 0.016964152453544382\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 75.15625%\n",
      "Epoch 10/10, Loss: 0.014325462668177821\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 69.53125%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34a6fb1-d871-4ee9-a973-6368d9a1b18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.11218855904409536\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 91.71875%\n",
      "Epoch 2/20, Loss: 0.06695223833145746\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 89.84375%\n",
      "Epoch 3/20, Loss: 0.03683269498091294\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 79.6875%\n",
      "Epoch 4/20, Loss: 0.04286207785855613\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 80.78125%\n",
      "Epoch 5/20, Loss: 0.03954696873409325\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 82.96875%\n",
      "Epoch 6/20, Loss: 0.03361854456851482\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 71.25%\n",
      "Epoch 7/20, Loss: 0.018811177844170943\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 83.125%\n",
      "Epoch 8/20, Loss: 0.01588556774109145\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 76.25%\n",
      "Epoch 9/20, Loss: 0.014490372336220868\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 72.34375%\n",
      "Epoch 10/20, Loss: 0.022328842988430932\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 84.0625%\n",
      "Epoch 11/20, Loss: 0.03080401445172607\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 68.28125%\n",
      "Epoch 12/20, Loss: 0.018966904803733784\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 75.625%\n",
      "Epoch 13/20, Loss: 0.005706687433950407\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 76.40625%\n",
      "Epoch 14/20, Loss: 0.008290907702540368\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 74.6875%\n",
      "Epoch 15/20, Loss: 0.03662764815710223\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 82.34375%\n",
      "Epoch 16/20, Loss: 0.011413852127109197\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 73.125%\n",
      "Epoch 17/20, Loss: 0.010522092373594763\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 80.9375%\n",
      "Epoch 18/20, Loss: 0.024564345435492827\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 70.9375%\n",
      "Epoch 19/20, Loss: 0.009227052456380598\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 75.0%\n",
      "Epoch 20/20, Loss: 0.01055056196180584\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 74.0625%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa071e9-1079-487f-ba71-c15975edccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3943423063385706\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 81.875%\n",
      "Epoch 2/5, Loss: 0.19106377464679122\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 64.0625%\n",
      "Epoch 3/5, Loss: 0.1545540467818822\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 75.3125%\n",
      "Epoch 4/5, Loss: 0.1311975587273668\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 66.09375%\n",
      "Epoch 5/5, Loss: 0.10584247081134857\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 84.21875%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05566456-0172-4fd3-b8bf-23cf1a6d7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.2805045916716014\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 82.03125%\n",
      "Epoch 2/10, Loss: 0.17119593912609882\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 73.75%\n",
      "Epoch 3/10, Loss: 0.13000891027412165\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 85.78125%\n",
      "Epoch 4/10, Loss: 0.11376636450184635\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 65.0%\n",
      "Epoch 5/10, Loss: 0.10617766787006629\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 86.40625%\n",
      "Epoch 6/10, Loss: 0.11557284679743776\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 76.71875%\n",
      "Epoch 7/10, Loss: 0.09871787937255176\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 80.3125%\n",
      "Epoch 8/10, Loss: 0.08748861409700905\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 70.9375%\n",
      "Epoch 9/10, Loss: 0.070153522408036\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 84.21875%\n",
      "Epoch 10/10, Loss: 0.08244090593431397\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 82.96875%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40aafa59-df4d-44a8-ab87-3d3f2b3ac40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.3160545587813927\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 80.3125%\n",
      "Epoch 2/20, Loss: 0.15614709733453996\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 77.03125%\n",
      "Epoch 3/20, Loss: 0.14227613378773254\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 70.15625%\n",
      "Epoch 4/20, Loss: 0.15226348959183766\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 71.5625%\n",
      "Epoch 5/20, Loss: 0.11743746143680044\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 75.625%\n",
      "Epoch 6/20, Loss: 0.10876394359200645\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 74.0625%\n",
      "Epoch 7/20, Loss: 0.0945434462753313\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 81.71875%\n",
      "Epoch 8/20, Loss: 0.09319331600370766\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 70.46875%\n",
      "Epoch 9/20, Loss: 0.07962790017296201\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 69.53125%\n",
      "Epoch 10/20, Loss: 0.07509855515440708\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 69.53125%\n",
      "Epoch 11/20, Loss: 0.073569450466008\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 82.5%\n",
      "Epoch 12/20, Loss: 0.061883273972998275\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 80.0%\n",
      "Epoch 13/20, Loss: 0.06767919807383459\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 73.125%\n",
      "Epoch 14/20, Loss: 0.04858508139121649\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 76.25%\n",
      "Epoch 15/20, Loss: 0.05243664991147702\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 75.9375%\n",
      "Epoch 16/20, Loss: 0.046471034333772636\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 67.65625%\n",
      "Epoch 17/20, Loss: 0.030918633963832733\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 86.40625%\n",
      "Epoch 18/20, Loss: 0.041488346576610685\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 72.8125%\n",
      "Epoch 19/20, Loss: 0.03231326141608936\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 82.96875%\n",
      "Epoch 20/20, Loss: 0.021028541245707025\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 72.34375%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11937dc2-c408-48df-b00c-9e04f7ff0f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3822471834719181\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 71.875%\n",
      "Epoch 2/5, Loss: 0.18419288914719242\n",
      "Validation Accuracy: 43.75%\n",
      "Test Accuracy: 64.21875%\n",
      "Epoch 3/5, Loss: 0.17312933490868726\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 62.65625%\n",
      "Epoch 4/5, Loss: 0.14194560226944328\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 66.09375%\n",
      "Epoch 5/5, Loss: 0.1363069166206509\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 78.90625%\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(10),      # Randomly rotate the images by 10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation and Test transform does not need augmentation, only resizing and normalization\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply the updated transforms to datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "404dddc9-a671-4acd-a240-5daa851d8b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.14313051072549235\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 88.59375%\n",
      "Epoch 2/5, Loss: 0.08341111398324873\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 87.34375%\n",
      "Epoch 3/5, Loss: 0.07736729906923337\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 77.8125%\n",
      "Epoch 4/5, Loss: 0.06528785659223109\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 84.53125%\n",
      "Epoch 5/5, Loss: 0.055983200022219425\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 81.875%\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(10),      # Randomly rotate the images by 10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation and Test transform does not need augmentation, only resizing and normalization\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply the updated transforms to datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c610194-5e38-4e8a-894e-f4d39ab14292",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(10),      # Randomly rotate the images by 10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation and Test transform does not need augmentation, only resizing and normalization\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply the updated transforms to datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df0338d-5510-40a5-bca6-a81817a55981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.14847090108994326\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 70.3125%\n",
      "Epoch 2/20, Loss: 0.08260875935466286\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 90.46875%\n",
      "Epoch 3/20, Loss: 0.07599873047756271\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 64.21875%\n",
      "Epoch 4/20, Loss: 0.07144786422555136\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 83.125%\n",
      "Epoch 5/20, Loss: 0.06761805377072123\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 74.6875%\n",
      "Epoch 6/20, Loss: 0.05170202455226263\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 84.6875%\n",
      "Epoch 7/20, Loss: 0.07316397230906492\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 75.3125%\n",
      "Epoch 8/20, Loss: 0.04355317764548425\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 77.03125%\n",
      "Epoch 9/20, Loss: 0.05352595068608622\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 84.375%\n",
      "Epoch 10/20, Loss: 0.043679054630091814\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 84.84375%\n",
      "Epoch 11/20, Loss: 0.03595333333656426\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 87.65625%\n",
      "Epoch 12/20, Loss: 0.045746906891899426\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 76.25%\n",
      "Epoch 13/20, Loss: 0.04264523496814186\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 78.59375%\n",
      "Epoch 14/20, Loss: 0.03777799939894206\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 84.375%\n",
      "Epoch 15/20, Loss: 0.03703763244989288\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 84.84375%\n",
      "Epoch 16/20, Loss: 0.044358568155510994\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 88.4375%\n",
      "Epoch 17/20, Loss: 0.034426353409107165\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 84.375%\n",
      "Epoch 18/20, Loss: 0.03374421215802574\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 82.34375%\n",
      "Epoch 19/20, Loss: 0.03210519103930072\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 83.28125%\n",
      "Epoch 20/20, Loss: 0.03278942145903572\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 84.21875%\n"
     ]
    }
   ],
   "source": [
    "#finally used this one in the report\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(10),      # Randomly rotate the images by 10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation and Test transform does not need augmentation, only resizing and normalization\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply the updated transforms to datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load a pre-trained ResNet-18\n",
    "\n",
    "# Modify the final layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)  # Replace with your number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe02fd-a41e-4fe4-a05c-dda7c85874fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
