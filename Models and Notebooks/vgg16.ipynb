{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973efde2-dbae-4efb-a6c1-eefd3933a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 on augmented data and epochs\n",
    "#used this in the report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(10),      # Randomly rotate the images by 10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation and Test transform does not need augmentation, only resizing and normalization\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply the updated transforms to datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fca483-4222-43e7-84ac-90c8e885f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.4413922432262988\n",
      "Epoch 1, Validation Accuracy: 93.75%\n",
      "Epoch 1, Test Accuracy: 88.14%\n",
      "Epoch 2/20, Training Loss: 0.24962903178983334\n",
      "Epoch 2, Validation Accuracy: 100.00%\n",
      "Epoch 2, Test Accuracy: 83.49%\n",
      "Epoch 3/20, Training Loss: 0.2313819032703795\n",
      "Epoch 3, Validation Accuracy: 100.00%\n",
      "Epoch 3, Test Accuracy: 86.86%\n",
      "Epoch 4/20, Training Loss: 0.15431607505344097\n",
      "Epoch 4, Validation Accuracy: 100.00%\n",
      "Epoch 4, Test Accuracy: 81.41%\n",
      "Epoch 5/20, Training Loss: 0.20874274484088295\n",
      "Epoch 5, Validation Accuracy: 100.00%\n",
      "Epoch 5, Test Accuracy: 84.94%\n",
      "Epoch 6/20, Training Loss: 0.13106373870624602\n",
      "Epoch 6, Validation Accuracy: 100.00%\n",
      "Epoch 6, Test Accuracy: 85.58%\n",
      "Epoch 7/20, Training Loss: 0.13259256605888814\n",
      "Epoch 7, Validation Accuracy: 87.50%\n",
      "Epoch 7, Test Accuracy: 82.05%\n",
      "Epoch 8/20, Training Loss: 0.11334933135644218\n",
      "Epoch 8, Validation Accuracy: 100.00%\n",
      "Epoch 8, Test Accuracy: 88.62%\n",
      "Epoch 9/20, Training Loss: 0.15282195849426983\n",
      "Epoch 9, Validation Accuracy: 100.00%\n",
      "Epoch 9, Test Accuracy: 82.69%\n",
      "Epoch 10/20, Training Loss: 0.157855809473158\n",
      "Epoch 10, Validation Accuracy: 93.75%\n",
      "Epoch 10, Test Accuracy: 82.69%\n",
      "Epoch 11/20, Training Loss: 0.13880186951151433\n",
      "Epoch 11, Validation Accuracy: 100.00%\n",
      "Epoch 11, Test Accuracy: 89.10%\n",
      "Epoch 12/20, Training Loss: 0.1709611113441653\n",
      "Epoch 12, Validation Accuracy: 93.75%\n",
      "Epoch 12, Test Accuracy: 88.94%\n",
      "Epoch 13/20, Training Loss: 0.12395849977166426\n",
      "Epoch 13, Validation Accuracy: 81.25%\n",
      "Epoch 13, Test Accuracy: 74.84%\n",
      "Epoch 14/20, Training Loss: 0.1693770763597471\n",
      "Epoch 14, Validation Accuracy: 100.00%\n",
      "Epoch 14, Test Accuracy: 87.66%\n",
      "Epoch 15/20, Training Loss: 0.11161401189975477\n",
      "Epoch 15, Validation Accuracy: 100.00%\n",
      "Epoch 15, Test Accuracy: 84.78%\n",
      "Epoch 16/20, Training Loss: 0.12695626695490403\n",
      "Epoch 16, Validation Accuracy: 100.00%\n",
      "Epoch 16, Test Accuracy: 88.78%\n",
      "Epoch 17/20, Training Loss: 0.14918819297309693\n",
      "Epoch 17, Validation Accuracy: 100.00%\n",
      "Epoch 17, Test Accuracy: 85.10%\n",
      "Epoch 18/20, Training Loss: 0.08346103787732145\n",
      "Epoch 18, Validation Accuracy: 100.00%\n",
      "Epoch 18, Test Accuracy: 86.86%\n",
      "Epoch 19/20, Training Loss: 0.1104334441963169\n",
      "Epoch 19, Validation Accuracy: 93.75%\n",
      "Epoch 19, Test Accuracy: 85.74%\n",
      "Epoch 20/20, Training Loss: 0.08756081477426095\n",
      "Epoch 20, Validation Accuracy: 100.00%\n",
      "Epoch 20, Test Accuracy: 85.90%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze the feature layers (optional, if you want to fine-tune only the classifier)\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, 2)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg16.classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Function for training\n",
    "def train_model_vgg16(model, criterion, optimizer, train_loader, val_loader, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}, Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "# Example of how to call the train_model_vgg16 function\n",
    "# train_model_vgg16(vgg16, criterion, optimizer, train_loader, val_loader, epochs=5)\n",
    "\n",
    "# Train the model\n",
    "train_model_vgg16(vgg16, criterion, optimizer, train_loader, val_loader, epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46efad4-a222-4f51-aea0-bf655ce6b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd549452-8bd2-47f9-aadc-751557c85c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c9ac6-5d51-423f-a0ef-2a7c28dad08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d480a4-44b2-4b7f-be3c-348fdc3112de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c88ab4-c206-4ebb-a681-f0755a638cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8698048-3fe6-439f-af3c-99c19e683b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e131e-585a-4f3a-bf29-68039eb84e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b5dbc80-9497-4efe-ac63-63adb8225f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bf254-fa86-42bc-a4fa-274c74293f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a36b3f-97eb-4e2c-bd2f-8d885cbc080e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
