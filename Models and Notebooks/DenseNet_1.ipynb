{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6e4287-bc37-4702-9b62-928b17fb6042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pb2718/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/pb2718/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/pb2718/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████████████████████████████████| 30.8M/30.8M [00:00<00:00, 49.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3451741684936673\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 39.26282051282051%\n",
      "Epoch 2/5, Loss: 0.22869363510581248\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 66.66666666666667%\n",
      "Epoch 3/5, Loss: 0.1845726004167477\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 74.35897435897436%\n",
      "Epoch 4/5, Loss: 0.15176031376275181\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 67.46794871794872%\n",
      "Epoch 5/5, Loss: 0.12058737864317887\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 85.57692307692308%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained DenseNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1810078-4109-4b08-ab13-69b6df764d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.3357010281936157\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 64.90384615384616%\n",
      "Epoch 2/10, Loss: 0.19934576475547136\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 82.6923076923077%\n",
      "Epoch 3/10, Loss: 0.18527860160162843\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 64.26282051282051%\n",
      "Epoch 4/10, Loss: 0.18020469222240654\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 82.8525641025641%\n",
      "Epoch 5/10, Loss: 0.1401381854973505\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 82.37179487179488%\n",
      "Epoch 6/10, Loss: 0.15124957751414161\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 83.01282051282051%\n",
      "Epoch 7/10, Loss: 0.1247559146601364\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 75.80128205128206%\n",
      "Epoch 8/10, Loss: 0.11901667750114861\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 64.58333333333333%\n",
      "Epoch 9/10, Loss: 0.10001425033983735\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 75.96153846153847%\n",
      "Epoch 10/10, Loss: 0.09811847218729418\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 82.6923076923077%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained DenseNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f55b39-1073-460b-ae7a-1f67dc8593c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.37006961785119735\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 71.7948717948718%\n",
      "Epoch 2/20, Loss: 0.17115095540012684\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 86.21794871794872%\n",
      "Epoch 3/20, Loss: 0.14433825886208404\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 80.12820512820512%\n",
      "Epoch 4/20, Loss: 0.12584149515816223\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 81.57051282051282%\n",
      "Epoch 5/20, Loss: 0.10994711456580396\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 70.3525641025641%\n",
      "Epoch 6/20, Loss: 0.09239219831291334\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 79.16666666666667%\n",
      "Epoch 7/20, Loss: 0.09574225243249554\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 70.67307692307692%\n",
      "Epoch 8/20, Loss: 0.08293739236474175\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 73.87820512820512%\n",
      "Epoch 9/20, Loss: 0.08243559658287401\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 73.87820512820512%\n",
      "Epoch 10/20, Loss: 0.10164431455985078\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 73.71794871794872%\n",
      "Epoch 11/20, Loss: 0.08000253264626568\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 78.84615384615384%\n",
      "Epoch 12/20, Loss: 0.06170170966741498\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 77.24358974358974%\n",
      "Epoch 13/20, Loss: 0.06709208180613678\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 64.74358974358974%\n",
      "Epoch 14/20, Loss: 0.06653628694293506\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 79.96794871794872%\n",
      "Epoch 15/20, Loss: 0.06145981324770905\n",
      "Validation Accuracy: 50.0%\n",
      "Test Accuracy: 65.38461538461539%\n",
      "Epoch 16/20, Loss: 0.055602711992498284\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 75.80128205128206%\n",
      "Epoch 17/20, Loss: 0.05680182758515895\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 68.10897435897436%\n",
      "Epoch 18/20, Loss: 0.053672186788914306\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 78.2051282051282%\n",
      "Epoch 19/20, Loss: 0.041812096145703956\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 68.75%\n",
      "Epoch 20/20, Loss: 0.03960853431872349\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 72.75641025641026%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained DenseNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "449e01d6-632e-498d-9819-5b52f26fb4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.11628864235616078\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 80.12820512820512%\n",
      "Epoch 2/5, Loss: 0.06818570632578953\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 83.65384615384616%\n",
      "Epoch 3/5, Loss: 0.05974887684916083\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 87.01923076923077%\n",
      "Epoch 4/5, Loss: 0.04973661376840429\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 83.17307692307692%\n",
      "Epoch 5/5, Loss: 0.037795042294860345\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 75.32051282051282%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained DenseNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7646e876-e84c-4a26-bb59-d9e77d2e5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.11843566361249087\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 80.28846153846153%\n",
      "Epoch 2/10, Loss: 0.0666104334198007\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 69.23076923076923%\n",
      "Epoch 3/10, Loss: 0.055987437491368024\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 80.44871794871794%\n",
      "Epoch 4/10, Loss: 0.04369798376999132\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 86.37820512820512%\n",
      "Epoch 5/10, Loss: 0.04718165333281726\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 68.10897435897436%\n",
      "Epoch 6/10, Loss: 0.03459929024455698\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 73.23717948717949%\n",
      "Epoch 7/10, Loss: 0.03058550587231779\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 74.67948717948718%\n",
      "Epoch 8/10, Loss: 0.030112531644105055\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 77.24358974358974%\n",
      "Epoch 9/10, Loss: 0.023803281490483885\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 83.97435897435898%\n",
      "Epoch 10/10, Loss: 0.03235817608786704\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 79.48717948717949%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained DenseNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01e704f-3cb3-48db-8c37-0c834404569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.112633762658328\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 85.09615384615384%\n",
      "Epoch 2/20, Loss: 0.06339677591505317\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 85.41666666666667%\n",
      "Epoch 3/20, Loss: 0.07588177232394577\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 68.91025641025641%\n",
      "Epoch 4/20, Loss: 0.05115880547955552\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 75.32051282051282%\n",
      "Epoch 5/20, Loss: 0.03875792964841553\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 68.42948717948718%\n",
      "Epoch 6/20, Loss: 0.04424564962623858\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 82.37179487179488%\n",
      "Epoch 7/20, Loss: 0.041137181823084734\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 87.17948717948718%\n",
      "Epoch 8/20, Loss: 0.03257083516503489\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 74.51923076923077%\n",
      "Epoch 9/20, Loss: 0.025131883175604035\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 79.00641025641026%\n",
      "Epoch 10/20, Loss: 0.026066151327161443\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 68.91025641025641%\n",
      "Epoch 11/20, Loss: 0.04444316180674302\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 81.89102564102564%\n",
      "Epoch 12/20, Loss: 0.017546319776015395\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 74.03846153846153%\n",
      "Epoch 13/20, Loss: 0.009637967191544698\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 79.16666666666667%\n",
      "Epoch 14/20, Loss: 0.018427675821499876\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 81.25%\n",
      "Epoch 15/20, Loss: 0.01917523450782675\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 74.35897435897436%\n",
      "Epoch 16/20, Loss: 0.0330797381851925\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 76.4423076923077%\n",
      "Epoch 17/20, Loss: 0.01173667426075241\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 83.17307692307692%\n",
      "Epoch 18/20, Loss: 0.010071600624313275\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 81.08974358974359%\n",
      "Epoch 19/20, Loss: 0.030090800629212003\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 73.71794871794872%\n",
      "Epoch 20/20, Loss: 0.03363072746104784\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 78.2051282051282%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to 256x256 pixels\n",
    "    transforms.ToTensor(),          # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained DenseNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99b1796-a4a3-4f9f-8f89-2b13df852707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.13660085375243627\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 82.05128205128206%\n",
      "Epoch 2/20, Loss: 0.089050859218589\n",
      "Validation Accuracy: 56.25%\n",
      "Test Accuracy: 64.26282051282051%\n",
      "Epoch 3/20, Loss: 0.0922898639756272\n",
      "Validation Accuracy: 87.5%\n",
      "Test Accuracy: 84.93589743589743%\n",
      "Epoch 4/20, Loss: 0.06954126487817455\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 73.71794871794872%\n",
      "Epoch 5/20, Loss: 0.07405919526086584\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 89.90384615384616%\n",
      "Epoch 6/20, Loss: 0.059255331266168616\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 80.44871794871794%\n",
      "Epoch 7/20, Loss: 0.06224928193645655\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 75.64102564102564%\n",
      "Epoch 8/20, Loss: 0.050460484300945754\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 91.82692307692308%\n",
      "Epoch 9/20, Loss: 0.05190447499715592\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 82.05128205128206%\n",
      "Epoch 10/20, Loss: 0.05050051784174277\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 87.01923076923077%\n",
      "Epoch 11/20, Loss: 0.041653691036619554\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 83.17307692307692%\n",
      "Epoch 12/20, Loss: 0.0602361112022401\n",
      "Validation Accuracy: 75.0%\n",
      "Test Accuracy: 75.96153846153847%\n",
      "Epoch 13/20, Loss: 0.04670732329632413\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 87.33974358974359%\n",
      "Epoch 14/20, Loss: 0.042372177200009076\n",
      "Validation Accuracy: 68.75%\n",
      "Test Accuracy: 85.41666666666667%\n",
      "Epoch 15/20, Loss: 0.0429702252974488\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 76.6025641025641%\n",
      "Epoch 16/20, Loss: 0.03661346138616384\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 84.93589743589743%\n",
      "Epoch 17/20, Loss: 0.03603739695080008\n",
      "Validation Accuracy: 93.75%\n",
      "Test Accuracy: 83.81410256410257%\n",
      "Epoch 18/20, Loss: 0.04864419788405002\n",
      "Validation Accuracy: 62.5%\n",
      "Test Accuracy: 79.16666666666667%\n",
      "Epoch 19/20, Loss: 0.03891033680416412\n",
      "Validation Accuracy: 100.0%\n",
      "Test Accuracy: 85.73717948717949%\n",
      "Epoch 20/20, Loss: 0.03490951910605683\n",
      "Validation Accuracy: 81.25%\n",
      "Test Accuracy: 83.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "#finally used this one in the report\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(10),      # Randomly rotate the images by 10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation and Test transform does not need augmentation, only resizing and normalization\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply the updated transforms to datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root='val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Load a pre-trained DenseNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the final classifier layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you are using a GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aceaa9d-3b01-467a-a732-2b58b0550ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
