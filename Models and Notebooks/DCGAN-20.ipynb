{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7443f76-aa7b-48db-b15f-097fadc15b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms as T,datasets,models\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.nn import Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23983dd6-9bde-4153-8a14-1a38bef83dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transforms(phase = None):\n",
    "    \n",
    "    if phase == 'train':\n",
    "\n",
    "        data_T = T.Compose([\n",
    "            \n",
    "                T.Resize(size = (256,256)),\n",
    "                T.RandomRotation(degrees = (-20,+20)),\n",
    "                T.CenterCrop(size=224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "\n",
    "        data_T = T.Compose([\n",
    "\n",
    "                T.Resize(size = (224,224)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    return data_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2e5664-95f4-4206-bb2b-f63f3eb49e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/Anil/Downloads/archive/chest_xray\"\n",
    "\n",
    "trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'),transform = data_transforms('train'))\n",
    "testset = datasets.ImageFolder(os.path.join(data_dir, 'test'),transform = data_transforms('test'))\n",
    "validset = datasets.ImageFolder(os.path.join(data_dir, 'val'),transform = data_transforms('val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c0be92-1974-4f4a-943e-ff36b11cb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f962802f-e7f9-424d-950d-526530b5d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset,batch_size = 64,shuffle = True)\n",
    "validloader = DataLoader(validset,batch_size = 64,shuffle = True)\n",
    "testloader = DataLoader(testset,batch_size = 64,shuffle = True)\n",
    "\n",
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc998bc-1dc0-4ac3-981c-bdd84a054ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images,labels) in enumerate(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7806aff4-e905-4338-aa1c-7996fabf20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 64, (4, 4), (2, 2), (1, 1), bias=True),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(64, 128, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(128, 256, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(256, 512, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(512, 1, (4, 4), (1, 1), (0, 0), bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        out = torch.flatten(out, 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3ab70e-2cd9-4189-98aa-f8421af70a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69368adc-4439-4233-bfa4-068844472f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dbfdb4-2509-4d16-a23c-52ea9a068e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f5419d-bd19-459d-8304-e9af71504596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f3365a-fb02-4ebd-9d38-89487418354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           3,136\n",
      "         LeakyReLU-2         [-1, 64, 112, 112]               0\n",
      "            Conv2d-3          [-1, 128, 56, 56]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 56, 56]             256\n",
      "         LeakyReLU-5          [-1, 128, 56, 56]               0\n",
      "            Conv2d-6          [-1, 256, 28, 28]         524,288\n",
      "       BatchNorm2d-7          [-1, 256, 28, 28]             512\n",
      "         LeakyReLU-8          [-1, 256, 28, 28]               0\n",
      "            Conv2d-9          [-1, 512, 14, 14]       2,097,152\n",
      "      BatchNorm2d-10          [-1, 512, 14, 14]           1,024\n",
      "        LeakyReLU-11          [-1, 512, 14, 14]               0\n",
      "           Conv2d-12            [-1, 1, 11, 11]           8,193\n",
      "          Sigmoid-13            [-1, 1, 11, 11]               0\n",
      "================================================================\n",
      "Total params: 2,765,633\n",
      "Trainable params: 2,765,633\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 28.33\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 39.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (images.shape[1], images.shape[2], images.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca22321b-b65e-4e06-9e39-e081de016a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 3.923244833946228\n",
      "Epoch 2 - Training loss: 3.86826235492055\n",
      "Epoch 3 - Training loss: 3.8562225888415083\n",
      "Epoch 4 - Training loss: 3.8538341551292232\n",
      "Epoch 5 - Training loss: 3.8491066025524603\n",
      "Epoch 6 - Training loss: 3.856597720122919\n",
      "Epoch 7 - Training loss: 3.853225652764483\n",
      "Epoch 8 - Training loss: 3.8498688645479158\n",
      "Epoch 9 - Training loss: 3.848143493256918\n",
      "Epoch 10 - Training loss: 3.8458196826097444\n",
      "Epoch 11 - Training loss: 3.8439349401287917\n",
      "Epoch 12 - Training loss: 3.8462044872888703\n",
      "Epoch 13 - Training loss: 3.847195180450998\n",
      "Epoch 14 - Training loss: 3.8445214847239053\n",
      "Epoch 15 - Training loss: 3.8434906645518976\n",
      "Epoch 16 - Training loss: 3.8443543649301297\n",
      "Epoch 17 - Training loss: 3.8438061533904655\n",
      "Epoch 18 - Training loss: 3.8448136637850507\n",
      "Epoch 19 - Training loss: 3.843256208954788\n",
      "Epoch 20 - Training loss: 3.84276822427424\n"
     ]
    }
   ],
   "source": [
    "Losses = []\n",
    "for i in range(20): #I noticed very little change in the loss, so keeping the epochs low\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        Losses.append(loss)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e94469c5-de8a-4993-800a-9305681603f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 624\n",
      "\n",
      "Model Accuracy = 0.3766025641025641\n"
     ]
    }
   ],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images,labels in testloader:\n",
    "  for i in range(len(labels)):\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "    img = images[i].view(1, 3, 224, 224)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.cpu()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.cpu()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383fd97-865b-4c93-824f-24a5f4ed9952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
